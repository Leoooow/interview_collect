# AI Agent Engineer 面试准备指南

> 面试公司/部门：语音智能体后端团队
> 面试官技术栈：Java/Kotlin + Spring Boot + gRPC + Redis + Kafka
> 准备日期：2026-02-03

---

## 一、面试官画像分析

### 1.1 技术背景推断
根据技术栈描述（Java/Kotlin、Spring Boot、gRPC、Redis、Kafka），面试官很可能是：
- **资深后端工程师**：精通Java微服务架构
- **分布式系统专家**：熟悉Kafka消息队列、Redis集群
- **实时系统经验**：有语音智能体、流式处理背景
- **可能的工作年限**：5-10年+，技术深度较强

### 1.2 面试官可能的关注点
1. **工程能力**：分布式系统、高并发、稳定性
2. **AI工程化**：如何将LLM集成到生产系统
3. **系统设计**：架构决策、trade-off分析
4. **问题解决**：生产事故排查、性能优化
5. **技术广度**：对语音系统的理解（ASR/TTS、WebRTC）

---

## 二、JD关键要求与你的匹配度分析

| JD要求 | 你的背景 | 匹配度 | 应对策略 |
|--------|----------|--------|----------|
| Java/Kotlin后端 | 熟悉Java | ⭐⭐⭐ | 强调AI平台开发中的Java使用，但需补强Spring Boot经验 |
| LLM集成 | HiAgent、Dify经验 | ⭐⭐⭐⭐⭐ | **强项**，重点展开 |
| 语音智能体 | 无直接经验 | ⭐⭐ | 诚实承认，强调可迁移性（实时性、流式处理概念） |
| RAG管道 | 核心项目经验 | ⭐⭐⭐⭐⭐ | **强项**，深入准备 |
| 云平台 | 有使用经验 | ⭐⭐⭐ | 准备具体案例 |
| WebSocket/实时通信 | 未明确提及 | ⭐⭐ | 补充学习基础概念 |

---

## 三、简历深挖问题预测

### 3.1 智能体开发平台项目（最核心，必问）

#### Q1: "你提到从Dify迁移到HiAgent平台，能详细说说这个迁移过程吗？"

**考察点**：技术选型、迁移策略、架构理解

**推荐回答结构**：
```
1. 背景说明
   - 业务需求：开源Dify在性能、功能、企业级特性上无法满足
   - 迁移目标：保持业务连续性的同时提升平台能力

2. 迁移策略
   - 兼容性分析：对比Dify和HiAgent的API、数据结构差异
   - 渐进式迁移：先迁移非关键业务，逐步切换核心业务
   - 工具开发：开发转换工具处理历史数据、配置迁移

3. 我负责的部分
   - 文档解析插件：支持PDF/Word/Markdown，集成OCR处理图片
   - 邮件工具：封装内部邮件API，实现Agent调用邮件发送功能
   - 能力补齐：识别HiAgent缺失的原Dify功能，开发替代方案

4. 遇到的挑战
   - API差异导致的适配工作
   - 历史数据迁移的一致性保证
   - 业务方的平滑过渡

5. 结果
   - 5个业务方成功迁移
   - 平台稳定性和性能提升
   - 内部知识库沉淀
```

**追问准备**：
- "HiAgent和Dify的架构差异是什么？" → 谈论插件系统、API设计
- "如何保证迁移过程中的数据一致性？" → 事务性、回滚方案、灰度发布

---

#### Q2: "你提到在客服场景提升10%指标，具体做了哪些优化？"

**考察点**：RAG优化、提示工程、效果评估

**推荐回答结构**：
```
1. 问题诊断
   - 客服场景的痛点：回答不准确、检索不相关、响应慢
   - 数据分析：收集bad case，分析失败模式（召回问题/理解问题/生成问题）

2. 优化措施（分阶段）
   a) 检索优化
      - 文档解析优化：表格、列表结构的准确提取
      - 分块策略：语义分块 vs 固定长度分块
      - 检索策略：混合检索（向量+关键词）、重排序（Rerank）
      - 向量索引：FAISS/HNSW加速检索

   b) 提示工程
      - 角色设定：明确客服助手的人设和职责边界
      - Few-shot示例：从历史优质对话中提取模板
      - 结构化输出：要求模型按固定格式返回，便于后处理
      - 思维链：复杂问题拆解成多步推理

   c) 工作流设计
      - 意图识别：先判断问题类型，路由到不同处理链路
      - 多轮对话：上下文记忆管理，关键信息提取
      - 安全护栏：敏感信息过滤、拒绝回答不当问题

3. 效果评估
   - 离线指标：准确率、召回率、F1、响应时间
   - 线上指标：用户满意度、问题解决率、转人工率
   - 最终成果：关键指标提升10%

4. 经验总结
   - RAG是系统工程，需要端到端优化
   - 数据质量比模型更重要
   - 持续迭代：建立评估→优化→上线的闭环
```

**追问准备**：
- "如何评估RAG的效果？" → 离线评估（RAGAS）、线上AB测试
- "向量检索和关键词检索怎么结合？" → 混合检索、权重调优
- "如何处理文档中的表格和图片？" → 专门解析器、OCR

---

#### Q3: "你开发的平台答疑智能体，架构是怎样的？"

**考察点**：系统设计、全栈能力

**推荐回答结构**：
```
1. 需求分析
   - 目标：降低内部支持成本，快速响应平台使用问题
   - 用户：开发者和业务方，技术水平参差不齐

2. 整体架构
   - 知识库：平台文档、API文档、FAQ、历史工单
   - Agent层：
     * 意图识别：问题分类（使用问题/故障排查/功能咨询）
     * 检索增强：RAG获取相关文档片段
     * 答案生成：基于检索结果生成回答
   - 接入层：Slack/企业微信/Web Widget
   - 评估层：用户反馈收集、bad case分析

3. 技术选型
   - 向量数据库：Chroma/Milvus（根据实际情况说）
   - 框架：LangGraph编排Agent流程
   - 部署：容器化、K8s编排

4. 持续优化
   - 日均30次调用 → 收集真实问题
   - 问题解决率95%+ → 不满意case迭代
   - 知识库更新：新功能文档及时同步

5. 反思改进
   - 增加多模态支持（截图分析）
   - 代码示例生成
   - 与文档系统联动
```

---

### 3.2 大模型微调平台项目

#### Q4: "你提到使用Volcano调度系统，能说说为什么需要它吗？"

**考察点**：分布式系统、资源调度

**推荐回答结构**：
```
1. 背景
   - 需求：80卡连续360小时训练
   - 挑战：GPU资源昂贵，需要高效调度，避免资源浪费

2. 为什么用Volcano
   - K8s默认调度器不适合AI任务：
     * 不支持Gang Scheduling（所有任务同时成功或失败）
     * 不支持公平调度（大任务与小任务共存）
   - Volcano特性：
     * Gang Scheduling保证任务完整性
     * 队列管理、优先级调度
     * 支持Spark、MPI、PyTorch等AI框架

3. 我的贡献
   - 集成Volcano到训练平台
   - 设计调度策略：不同业务的优先级、资源配额
   - 压力测试：模拟多任务并发，验证调度稳定性
   - 监控告警：训练状态、资源使用、异常检测

4. 结果
   - 80卡360小时稳定训练
   - 资源利用率提升X%
   - 支持多业务并行训练
```

**追问准备**：
- "训练中损失震荡怎么定位的？" → 学习率、数据质量、梯度爆炸/消失
- "显存溢出如何解决？" → 梯度累积、混合精度、模型并行

---

### 3.3 RAG知识库优化项目

#### Q5: "你是如何将检索延迟降低40%的？"

**考察点**：性能优化、数据库优化

**推荐回答结构**：
```
1. 问题定位
   - 监控发现：检索延迟是主要瓶颈（平均X ms）
   - 分析工具：APM追踪、慢查询日志

2. 优化手段（组合拳）
   a) 向量索引优化
      - 从精确搜索切换到近似搜索（HNSW/IVF）
      - 调优索引参数（ef_construction、M）
      - 权衡精度与速度

   b) 分级检索策略
      - 热点数据缓存（Redis）：高频问题直接返回
      - 分层检索：先粗筛再精排，减少计算量
      - 异步更新：索引构建不阻塞主流程

   c) 基础设施优化
      - 数据库连接池调优
      - 批量查询合并
      - CDN加速静态资源

   d) 算法优化
      - Query改写：简化查询、去停用词
      - 降维：向量维度减少（768→256）
      - 量化：FP32→FP16

3. 效果
   - 延迟平均降低40%（X ms → Y ms）
   - 召回率保持稳定（仅下降0.X%）
   - P99延迟显著改善

4. 经验
   - 优化前先profiling，避免盲目优化
   - 建立基线指标，量化效果
   - 性能与精度的trade-off需要业务方认可
```

---

## 四、基于面试官背景的技术问题

### 4.1 Java/后端基础

#### Q6: "你在AI平台中使用Java，主要用了哪些框架和技术？"

**如果你的Java经验有限，建议这样回答**：
```
实话实说 + 突出学习能力和Python优势：

"我的主力语言是Python，但在AI平台开发中也使用了Java：

1. Java应用场景
   - 微服务间的API对接（Spring Boot）
   - 部分中间件的客户端（Kafka producer/consumer）
   - 遗留系统的维护和集成

2. 我的优势
   - Python生态：丰富的AI/ML库（LangChain、LlamaIndex）
   - 快速迭代：适合探索性开发、原型验证
   - Java基础：熟悉OOP、JVM、并发编程基础

3. 学习计划
   - 深入Spring Boot生态
   - 学习gRPC（从REST转向gRPC）
   - 补强分布式系统知识（一致性、CAP理论）

4. 个人看法
   - 语言是工具，关键是理解原理
   - AI工程需要Python和Java的互补
   - 我愿意投入时间补强Java栈
"

**如果面试官追问细节**：
- 转向你熟悉的部分：系统集成、API设计、数据流转
- 强调你理解的概念，而非死记硬背语法
```

---

#### Q7: "你对微服务架构的理解？"

**推荐回答**：
```
结合AI平台经验 + 补充理论知识：

1. 实践经验（来自AI平台）
   - 服务拆分：
     * Agent编排服务（工作流、工具调用）
     * 模型推理服务（LLM调用、embeddings）
     * RAG服务（向量检索、文档管理）
     * 用户管理服务（认证、配额）
   - 通信方式：REST API + 事件驱动（Kafka）
   - 服务治理：配置中心、服务发现、熔断降级

2. 遇到的挑战
   - 分布式事务：跨服务的数据一致性
   - 服务间调用：超时、重试、幂等性
   - 可观测性：链路追踪（Jaeger/Zipkin）

3. 理论理解（补强）
   - CAP定理： consistency vs availability
   - 最终一致性：BASE理论
   - 服务网格：Istio、流量管理

4. 反思
   - 不要过早拆分：初期单体服务更简单
   - 接口设计要向后兼容
   - 重视文档和测试
```

---

### 4.2 语音系统相关问题（高概率）

#### Q8: "你对语音智能体有什么了解？觉得和文本智能体有什么区别？"

**诚实回答 + 展示学习能力**：
```
"我没有直接的语音系统开发经验，但我从技术文档和论文中学习过：

1. 技术栈理解
   - ASR（自动语音识别）：语音→文本
   - TTS（文本转语音）：文本→语音
   - 端到端语音模型：GPT-4o Audio、Gemini Multimodal
   - 实时通信：WebSocket、WebRTC

2. 与文本Agent的区别
   - 延迟敏感：语音对话要求低延迟（<500ms），文本可容忍更高
   - 中断处理：用户随时可能打断，需要流式响应
   - 上下文管理：需要处理语音片段、停顿、重复
   - 情感表达：语气、语调、节奏也是信息

3. 可迁移的能力
   - 对话状态管理：文本和语音都需要
   - 工具调用：逻辑是相通的
   - RAG Pipeline：信息检索不依赖输入模态

4. 学习计划
   - 深入研究：WebRTC协议、音频处理基础
   - 实践项目：用Python实现简单的语音对话demo
   - 关注前沿：OpenAI Realtime API、GPT-4o的语音能力

5. 个人想法
   - 语音是AI交互的未来方向
   - 虽然我现在经验不足，但学习能力强
   - 愿意从基础做起，快速上手
"
```

---

#### Q9: "如何优化语音系统的端到端延迟？"

**基于你的知识回答**：
```
"从我的RAG优化经验出发，我会从这些方面考虑：

1. 全链路分析
   - ASR延迟：音频识别时间
   - 网络延迟：数据传输
   - LLM推理延迟：模型生成时间
   - TTS延迟：语音合成时间

2. 优化策略
   - 流式处理：不等音频结束就开始识别，不等LLM结束就开始播放
   - 模型选择：小模型+高质量提示，可能比大模型更快
   - 缓存：常见问题的预计算回答
   - 并行化：ASR的同时准备上下文，LLM生成的同时预加载TTS

3. 权衡
   - 延迟 vs 质量：更快的模型可能准确率更低
   - 成本 vs 性能：更多算力降低延迟
   - 用户体验：有时候"思考中"的提示比立即回答更好

4. 监控
   - 分段监控：找出瓶颈环节
   - P50/P95/P99：关注长尾延迟
   - 用户体验测试：真实感知延迟 vs 技术指标

我虽然没有语音系统的直接经验，但这些优化思路是通用的，我愿意深入学习语音系统的特殊性。
"
```

---

### 4.3 LLM集成与编排

#### Q10: "你们如何管理多个LLM提供商的切换？"

**你的强项，重点展开**：
```
"在HiAgent平台中，我们支持多种LLM：

1. 抽象层设计
   - 统一API：定义标准的LLM调用接口
     * chat(messages, model, temperature, ...)
     * stream_chat(...) 用于流式输出
   - 适配器模式：为每个提供商实现适配器
     * OpenAIAdapter
     * AzureAdapter
     * QwenAdapter（自研）
     * ClaudeAdapter
   - 配置化：模型选择、参数配置化

2. 智能路由
   - 场景化路由：
     * 简单问答 → 小模型（Qwen-7B）
     * 复杂推理 → 大模型（GPT-4/Claude）
     * 敏感数据 → 本地部署模型
   - 成本优化：根据token消耗和预算选择
   - 容灾备份：主模型失败时切换备用

3. 提示管理
   - 版本控制：Git管理提示词模板
   - A/B测试：不同提示版本的对比
   - 动态调整：根据模型能力调整提示

4. 监控与评估
   - 调用监控：延迟、成功率、成本
   - 效果评估：准确性、用户满意度
   - 模型benchmark：定期评估各模型表现

5. 经验
   - 不要过度依赖单一提供商
   - 不同模型的性格不同，需要针对性调优
   - 成本管理很重要，设置配额和告警
"
```

---

### 4.4 RAG系统设计

#### Q11: "如果让你设计一个支持百万级文档的RAG系统，你会怎么做？"

**展示系统设计能力**：
```
"结合我在荣耀的RAG优化经验，我会这样设计：

1. 整体架构
   - 数据接入层：文档解析（支持各种格式）
   - 处理层：分块、embeddings生成
   - 存储层：向量数据库（Milvus/Qdrant）+ 元数据存储
   - 检索层：混合检索（向量+关键词）+ 重排
   - 服务层：API网关、缓存、限流
   - 评估层：离线评估 + 在线监控

2. 核心技术选型
   - 向量数据库：Milvus（分布式、高性能）
   - 检索策略：两阶段（粗筛+精排）
   - 缓存：Redis热点缓存
   - 消息队列：Kafka异步处理

3. 扩展性设计
   - 水平扩展：向量数据库分片
   - 分级索引：热门文档独立索引
   - 异步处理：文档更新不阻塞服务
   - 多租户：数据隔离、配额管理

4. 性能优化
   - 索引优化：HNSW参数调优
   - 量化：向量降维、精度权衡
   - 批处理：批量embedding、批量检索
   - 预计算：高频问题缓存

5. 质量保障
   - 评估指标：召回率、准确率、MRR
   - 数据质量：文档解析准确性
   - A/B测试：对比不同策略
   - 人工反馈：bad case持续优化

6. 监控告警
   - 性能指标：P99延迟、QPS
   - 业务指标：用户满意度、解决率
   - 异常检测：检索失败率、空结果率
"
```

---

## 五、系统设计问题

### 5.1 高概率：设计一个语音客服系统

#### Q12: "设计一个支持电话接入的AI客服系统"

**完整回答框架**：
```
1. 需求澄清（先提问）
   - Q: 预期并发量？A: 假设1000并发
   - Q: 语音延迟要求？A: <1秒端到端
   - Q: 需要支持哪些功能？A: 问答、业务办理、转人工
   - Q: 部署环境？A: 云服务

2. 整体架构

   ┌─────────┐    ┌──────────┐    ┌──────────┐
   │ 用户电话 │───→│ 电信网关 │───→│ SIP服务器 │
   └─────────┘    └──────────┘    └──────────┘
                                         │
                                         ▼
   ┌──────────┐    ┌──────────┐    ┌──────────┐
   │ TTS引擎  │←───│ Agent服务 │←───│ ASR引擎  │
   └──────────┘    └──────────┘    └──────────┘
                           │
                    ┌──────┴──────┐
                    ▼             ▼
              ┌─────────┐   ┌─────────┐
              │ 向量DB  │   │  LLM   │
              └─────────┘   └─────────┘

3. 核心组件

   a) 接入层
      - SIP服务器：Asterisk/Kamailio处理电话接入
      - 媒体服务器：FreeSWITCH处理音频流
      - 协议转换：SIP ↔ WebSocket

   b) ASR/TTS层
      - ASR：Azure Speech / Google STT / Whisper
      - TTS：Azure TTS / Google TTS
      - 流式处理：边说边识别，降低延迟

   c) Agent编排层
      - 对话管理：会话状态、上下文、历史
      - 意图识别：NLU分类（查询/办理/投诉）
      - 工具调用：CRM查询、订单操作
      - 转接逻辑：复杂问题转人工

   d) 数据层
      - 向量数据库：Milvus存储知识库
      - 业务数据库：用户信息、订单
      - 缓存：Redis会话状态

4. 流程示例（查询订单）

   用户: "帮我查一下我的订单"
   │
   ├─1. ASR: 音频 → 文本
   ├─2. 意图识别: query_order
   ├─3. 实体提取: 缺少订单号
   ├─4. TTS: "请提供您的订单号"
   │
   用户: "订单号是123456"
   │
   ├─5. ASR识别
   ├─6. 工具调用: CRM.query_order("123456")
   ├─7. RAG检索: 查询相关政策、FAQ
   ├─8. LLM生成回答
   ├─9. TTS合成语音
   └─10. 播放给用户

5. 性能优化

   - 流式Pipeline: 不等所有环节完成
   - 模型选择: ASR用轻量模型，LLM用7B模型
   - 缓存: 常见问题预生成回答
   - 并行: ASR的同时准备上下文

6. 可靠性设计

   - 熔断降级: ASR/TTS失败时用备用服务
   - 超时处理: 单轮对话超时转人工
   - 监控告警: 延迟、成功率、用户满意度
   - 日志记录: 完整对话录音、用于分析

7. 成本控制

   - 模型选择: 简单场景用小模型
   - Token控制: 限制上下文长度
   - 智能路由: 能用规则就用规则

8. 扩展性考虑

   - 水平扩展: 无状态服务可水平扩展
   - 负载均衡: ASR/TTS/LLM独立扩容
   - 多区域部署: 降低网络延迟
```

---

## 六、行为面试问题

### 6.1 协作与沟通

#### Q13: "你提到支持5个业务方，如何处理他们的不同需求？"

**推荐回答（STAR法则）**：
```
Situation（背景）
"在HiAgent平台推广过程中，我同时支持客服、AIOps、代码审计等5个业务方，
每个业务方的需求和优先级都不同。"

Task（任务）
"我的任务是：
- 理解各业务方的核心需求
- 平衡平台能力与业务需求
- 确保所有业务方顺利上线"

Action（行动）
"1. 需求收集
   - 每周和业务方1on1沟通
   - 建立需求池，按优先级排序
   - 区分'必须要有'和'锦上添花'

2. 分阶段交付
   - MVP先行：先让业务方跑起来
   - 快速迭代：每周发布小版本
   - 功能模块化：不同功能独立交付

3. 知识沉淀
   - 编写最佳实践文档
   - 建立内部FAQ
   - 培训业务方自助服务

4. 预期管理
   - 明确告知开发周期
   - 坦诚沟通技术限制
   - 及时反馈进度变化"

Result（结果）
"结果：
- 5个业务方全部按时上线
- 平台答疑Agent降低支持成本
- 业务方满意度评分4.8/5
- 我被评为季度优秀员工"
```

---

### 6.2 问题解决

#### Q14: "描述一次你遇到的技术难题，以及如何解决的？"

**推荐回答**：
```
"大模型微调平台建设中的显存溢出问题：

背景：
- 业务方使用70B模型进行全量微调
- 在8卡A100上仍然OOM
- 训练任务频繁失败，影响业务进度

问题定位过程：
1. 分析显存占用：
   - 模型权重：70B * 2 bytes (FP16) ≈ 140GB
   - 梯度：相同大小
   - 优化器状态：Adam需要2倍梯度
   - 激活值：随batch size和序列长度增长

2. 瓶颈识别：
   - 优化器状态占用最大
   - batch size只能设为1
   - 序列长度受限

解决方案：
1. 技术方案：
   - 使用DeepSpeed ZeRO-3：分片优化器状态
   - 梯度检查点：换时间换空间
   - 混合精度训练：FP16+FP32混合
   - Flash Attention：降低激活值显存

2. 配置调优：
   - batch size调优：在显存允许下最大化
   - 梯度累积：模拟更大batch size
   - 序列截断：保留关键部分

3. 监控告警：
   - 实时监控各GPU显存
   - 预警机制：80%时告警
   - 自动备份：定期checkpoint

结果：
- 显存利用率从100%降至85%
- 训练稳定性大幅提升
- 支持更大batch size，训练加速2x
- 业务方顺利完成模型训练

反思：
- 问题要从根因分析，不能头痛医头
- 技术方案要结合业务约束
- 监控是系统稳定的基础"
```

---

### 6.3 持续学习

#### Q15: "你如何保持对AI技术的了解？"

**展示学习主动性**：
```
"我主要通过这些方式保持学习：

1. 学术前沿
   - 关注顶会论文（NeurIPS、ICLR、ACL）
   - 使用Papers with Code追踪SOTA
   - 参与论文复现项目

2. 工程实践
   - GitHub trending：发现新框架、工具
   - 开源项目贡献：给LangChain提PR
   - 个人项目：用GPT-4o Realtime做语音demo

3. 社区交流
   - Twitter/X关注AI研究者
   - Reddit r/LocalLLama了解社区动态
   - 参加线下meetup和技术分享

4. 技术博客
   - OpenAI/Anthropic官方博客
   - 各大云服务商的AI技术博客
   - 业界实践文章（Uber、Netflix等）

5. 实验验证
   - 定期尝新：测试新模型/新工具
   - Benchmark对比：不同方案的实际效果
   - 总结分享：团队内部分享会

最近的学习重点：
- 语音多模态：GPT-4o Audio、Realtime API
- Agent框架：LangGraph、AutoGen
- RAG优化：Advanced RAG patterns
- 模型部署：vLLM、TensorRT-LLM

我相信要保持竞争力，既要关注前沿，也要深入实践。
"
```

---

## 七、反向提问（问面试官的问题）

**提问目的**：
1. 展示你对职位的认真思考
2. 了解团队和项目实际情况
3. 判断是否适合自己

### 推荐问题

#### 1. 关于项目
"我看到JD提到语音智能体，想了解：
- 目前项目的进展？是在探索阶段还是已有产品？
- 团队的技术选型：是自研还是使用现成的语音解决方案？
- 面临的主要技术挑战是什么？"

#### 2. 关于团队
"团队目前的规模和结构？
- AI算法工程师和后端工程师的比例？
- 团队的技术栈是怎样的？
- 团队的工作方式（敏捷开发、code review流程等）？"

#### 3. 关于技术
"从JD看，团队使用Java/Kotlin + Spring Boot，我想了解：
- 为什么选择gRPC而不是REST？
- LLM方面，目前使用哪些模型和提供商？
- 如何评估Agent的效果？有专门的评估平台吗？"

#### 4. 关于业务
"语音智能体的主要应用场景是什么？
- 是客服、语音助手还是其他方向？
- 用户规模和并发量级？
- 有哪些成功案例或数据可以分享？"

#### 5. 关于成长
"这个职位对候选人的期待是什么？
- 希望在多长时间内能够独立负责模块？
- 团队对新技术探索的态度如何？
- 有没有技术分享、参加会议的机会？"

#### 6. 关于面试官
"您在这个团队工作了多久？
- 您个人最感兴趣的技术方向是什么？
- 您觉得这个职位最大的挑战是什么？"

---

## 八、面试准备清单

### 8.1 技术复习（按优先级）

- [ ] **RAG全链路**（必考）
  - [ ] 文档解析方法
  - [ ] 分块策略
  - [ ] 向量检索 vs 关键词检索
  - [ ] 重排（Rerank）算法
  - [ ] 评估指标（RAGAS、TruLens）

- [ ] **Agent架构**（必考）
  - [ ] LangGraph工作流设计
  - [ ] 工具调用机制
  - [ ] 记忆管理（短期/长期）
  - [ ] 规划（Planning）算法

- [ ] **LLM集成**（必考）
  - [ ] OpenAI/Azure/Claude API使用
  - [ ] 提示工程最佳实践
  - [ ] Function Calling
  - [ ] 流式输出处理

- [ ] **语音系统基础**（高频）
  - [ ] ASR/TTS工作原理
  - [ ] WebSocket实时通信
  - [ ] 音频处理基础（采样率、编码）
  - [ ] 延迟优化策略

- [ ] **后端基础**（补强）
  - [ ] Spring Boot核心概念
  - [ ] gRPC vs REST
  - [ ] Redis使用场景
  - [ ] Kafka消息队列

- [ ] **系统设计**（高频）
  - [ ] 微服务架构
  - [ ] 分布式系统CAP理论
  - [ ] 负载均衡策略
  - [ ] 缓存设计

### 8.2 简历项目梳理

每个项目准备3个层次：
1. **电梯演讲**（1分钟）：背景、挑战、结果
2. **技术细节**（5分钟）：架构、技术选型、实现
3. **深度挖掘**（15分钟）：遇到的问题、权衡、反思

### 8.3 行为面试准备

准备5个STAR故事，覆盖：
- [ ] 技术难题解决
- [ ] 跨团队协作
- [ ] 项目从0到1
- [ ] 生产事故处理
- [ ] 持续改进/优化

### 8.4 软技能展示

- **自信但谦逊**：承认不足（如语音经验），但展示学习能力
- **结构化表达**：先总后分，逻辑清晰
- **数据说话**：用具体数字证明效果
- **主动思考**：提问前先说明自己的理解

---

## 九、风险点与应对策略

### 9.1 明显短板

| 风险点 | 应对策略 |
|--------|----------|
| **工作年限短**（8个月） | 强调研究生期间的AI研究，展示快速成长能力，用具体成果说话 |
| **无语音经验** | 诚实承认 + 理论学习 + 愿意投入 + 可迁移能力 |
| **Java深度不足** | Python优势 + AI工程化经验 + 学习计划 |
| **分布式经验有限** | 微调平台的Volcano调度经验 + RAG系统优化经验 |

### 9.2 需要补强的知识

**紧急（面试前必看）**：
1. Spring Boot基础（IoC、AOP、自动配置）
2. gRPC vs REST的区别和使用场景
3. WebSocket实时通信原理
4. 语音系统基础知识（ASR/TTS流程）

**重要（有概念即可）**：
1. Redis数据结构和使用场景
2. Kafka消息队列
3. 微服务设计模式
4. 音频编解码基础

**加分（了解更好）**：
1. WebRTC协议
2. VoIP系统架构
3. 流式音频处理
4. 实时系统优化

---

## 十、面试当日注意事项

### 10.1 准备物品
- [ ] 简历打印版（2份）
- [ ] 笔记本电脑（可能需要写代码）
- [ ] 纸笔（画架构图）
- [ ] 项目演示（如果需要）

### 10.2 心态调整
- **这不是考试**：是双向选择，你也评估他们
- **不会就说**：诚实比不懂装懂更好
- **主动沟通**：不懂的地方可以反问
- **展示热情**：对AI技术的兴趣和投入

### 10.3 面试技巧
- **听清问题再回答**：可以复述确认理解
- **结构化表达**：用"第一、第二、第三"
- **给出具体例子**：不要空谈概念
- **控制时间**：每个问题3-5分钟，不要拖沓
- **展示思考过程**：可以说"让我思考一下"

### 10.4 可能的代码题
虽然不是纯算法岗，但可能考：
- LLM API调用封装
- RAG检索实现
- 简单的Agent工作流
- JSON数据处理
- 基础的数据结构操作

---

## 十一、最后的话

**你的优势**：
1. ✅ AI Agent实战经验（HiAgent、Dify）
2. ✅ RAG全链路优化经验
3. ✅ 多业务方支持经历
4. ✅ 学术背景（IJCAI论文）
5. ✅ 学习能力强（8个月快速成长）

**需要强调的**：
1. AI工程化能力：不仅仅是调包，而是理解原理
2. 解决问题的思路：从定位到验证到优化
3. 协作能力：跨团队合作、知识沉淀
4. 持续学习：跟进前沿、实验验证

**需要谨慎的**：
1. 不要夸大：做过就说做过，没做过就坦诚
2. 不要不懂装懂：可以说"我的理解是..."而不是确定地说
3. 不要贬低前公司：保持专业和积极

**记住**：
- 面试是平等的交流，不是审问
- 你的经历和成果有说服力
- 即使这次不成功，也是宝贵的学习机会
- 保持自信，展示最好的自己

---

**祝面试顺利！加油！** 🚀
